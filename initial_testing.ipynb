{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0bbc62-2502-43c0-ad7a-9495fcbaa4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.metrics import class_likelihood_ratios\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f279737-6cd0-4dc6-a2c3-63d6f81a4e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read emoticon dataset\n",
    "train_emoticon_df = pd.read_csv(\"datasets/train/train_emoticon.csv\")\n",
    "train_emoticon_X = train_emoticon_df['input_emoticon'].tolist()\n",
    "train_emoticon_Y = train_emoticon_df['label'].tolist()\n",
    "\n",
    "# read emoticon validation-set\n",
    "test_emoticon_df = pd.read_csv(\"datasets/valid/valid_emoticon.csv\")\n",
    "test_emoticon_X = test_emoticon_df['input_emoticon'].tolist()\n",
    "test_emoticon_Y = test_emoticon_df['label'].tolist()\n",
    "\n",
    "training_data_count = len(train_emoticon_X)\n",
    "validation_data_count = len(test_emoticon_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "867e8a27-7d6c-4c5e-9b19-5e857b270e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset in list format (list of [emozi_string, label])\n",
    "DATASET = []\n",
    "for i in range(training_data_count):\n",
    "    DATASET.append([train_emoticon_X[i], train_emoticon_Y[i]])\n",
    "\n",
    "VALIDATION_SET = []\n",
    "for i in range(validation_data_count):\n",
    "    VALIDATION_SET.append([test_emoticon_X[i], test_emoticon_Y[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff574f2e-5d1d-4675-bae8-0d3267b2eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return numpy array converting each emozi string to an integer array\n",
    "def to_unicode_decimal_array(emozi_string):\n",
    "    arr = [int(emozi.encode(\"unicode_escape\").hex(),16) for emozi in emozi_string]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09d62b25-764d-4842-8153-ee89c2e56fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    " # size in fraction of complete dataset, dataset randomized if 'randomized == True'\n",
    "def pick_dataset(size, randomized = True, to_int = False):\n",
    "    data_copy = deepcopy(DATASET)\n",
    "    if(randomized == True):\n",
    "        np.random.shuffle(data_copy)\n",
    "    req_split = data_copy[:int(size*training_data_count)]\n",
    "    if(to_int == True):\n",
    "        mod_split = [[to_unicode_decimal_array(data_point[0]),data_point[1]] for data_point in req_split]\n",
    "    else:\n",
    "        mod_split = [[data_point[0],data_point[1]] for data_point in req_split]\n",
    "    return mod_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c4d3bc-ae20-457b-bf76-5211094deb33",
   "metadata": {},
   "source": [
    "<h3>Approach 1: convert catagorical data to floating point numbers and train a model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c2ab351-0dc1-4425-ad88-dd545f8ff164",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_set = pick_dataset(size=1,randomized=True, to_int=True)\n",
    "test_set = [[to_unicode_decimal_array(data_point[0]),data_point[1]] for data_point in VALIDATION_SET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb1bfd00-f53c-4d20-9db0-5839082a45ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training set features and label array in numpy\n",
    "X = []\n",
    "for data in working_set:\n",
    "    X.append(data[0])\n",
    "X = np.array(X)\n",
    "\n",
    "Y = []\n",
    "for data in working_set:\n",
    "    Y.append(data[1])\n",
    "Y = np.array(Y)\n",
    "\n",
    "# creating validation set features and label array in numpy\n",
    "X_test = []\n",
    "for data in test_set:\n",
    "    X_test.append(data[0])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "Y_test = []\n",
    "for data in test_set:\n",
    "    Y_test.append(data[1])\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c4f17f2-0385-449f-8675-b9e8d35115a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize each feature to a value b/w 0 and !\n",
    "X_normed = (X-X.min(axis=0))/(X.max(axis=0)-X.min(axis=0));\n",
    "X_test_normed = (X_test-X_test.min(axis=0))/(X_test.max(axis=0)-X_test.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33b0c4f2-3810-4a97-893d-9e7acecbbe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF_classifier = svm.SVC(kernel='rbf', gamma='auto', C=1) # SVM with RBF kernel\n",
    "# RBF_classifier.fit(X_normed, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9be712f-23ff-4dc3-8b0d-b3ee82485dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP = 0\n",
    "# FP = 0\n",
    "# TN = 0\n",
    "# FN = 0\n",
    "# for i in range(len(X_normed)):\n",
    "#     prediction = RBF_classifier.predict([X_normed[i]])\n",
    "#     if((prediction == 0) and (Y[i] == 0)):\n",
    "#         TN+=1\n",
    "#     if((prediction == 0) and (Y[i] == 1)):\n",
    "#         FN+=1\n",
    "#     if((prediction == 1) and (Y[i] == 0)):\n",
    "#         FP+=1\n",
    "#     if((prediction == 1) and (Y[i] == 1)):\n",
    "#         TP+=1\n",
    "# train_accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "# print('training accuracy: ',train_accuracy)\n",
    "\n",
    "# TP = 0\n",
    "# FP = 0\n",
    "# TN = 0\n",
    "# FN = 0\n",
    "# for i in range(len(X_test_normed)):\n",
    "#     prediction = RBF_classifier.predict([X_test_normed[i]])\n",
    "#     if((prediction == 0) and (Y[i] == 0)):\n",
    "#         TN+=1\n",
    "#     if((prediction == 0) and (Y[i] == 1)):\n",
    "#         FN+=1\n",
    "#     if((prediction == 1) and (Y[i] == 0)):\n",
    "#         FP+=1\n",
    "#     if((prediction == 1) and (Y[i] == 1)):\n",
    "#         TP+=1\n",
    "# validation_accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "# print('validation accuracy: ',validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5430a6fd-d109-454b-91b6-05503e6ff81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## models that work with floating point features not working well with catagorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1826a84a-0b42-4b0c-994b-fac2646263ec",
   "metadata": {},
   "source": [
    "<h3>Approach 2: use Bag of words approach</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea4aee2b-d64d-4879-bc5b-00e75ce8b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "## imagine each emozi is a word having some meaning\n",
    "\n",
    "emozi_set = set()\n",
    "working_set = pick_dataset(1, randomized=True, to_int=False)\n",
    "for data in working_set:\n",
    "    features = data[0]\n",
    "    for emozi in features:\n",
    "        emozi_set.add(emozi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb3a85e0-0996-43aa-9474-544f7e00aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert each datapoint from training set into a sparse vector denoting presence of each emozi\n",
    "\n",
    "converted_dataset = []\n",
    "for datapoint in working_set:\n",
    "    converted_featuereset = np.zeros(len(emozi_set))\n",
    "    feature_list = deepcopy(datapoint[0])\n",
    "    pos = 0\n",
    "    for emozi in emozi_set:\n",
    "        if emozi in feature_list:\n",
    "            converted_featuereset[pos] = 1\n",
    "        pos+=1\n",
    "    converted_dataset.append([converted_featuereset,datapoint[1]])\n",
    "\n",
    "## convert each datapoint from validation set into a sparse vector\n",
    "\n",
    "converted_validation_set = []\n",
    "for datapoint in VALIDATION_SET:\n",
    "    converted_featuereset = np.zeros(len(emozi_set))\n",
    "    feature_list = deepcopy(datapoint[0])\n",
    "    pos = 0\n",
    "    for emozi in emozi_set:\n",
    "        if emozi in feature_list:\n",
    "            converted_featuereset[pos] = 1\n",
    "        pos+=1\n",
    "    converted_validation_set.append([converted_featuereset,datapoint[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3eee9603-0c99-44ca-a5c9-933dd0c175e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## preparing training data\n",
    "X = []\n",
    "y = []\n",
    "for data in converted_dataset:\n",
    "    X.append(data[0])\n",
    "    y.append(data[1])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "## preparing validation data\n",
    "X_v = []\n",
    "y_v = []\n",
    "for data in converted_validation_set:\n",
    "    X_v.append(data[0])\n",
    "    y_v.append(data[1])\n",
    "X_v = np.array(X_v)\n",
    "y_v = np.array(y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e269462-f261-4f61-94ef-27f2bcfce5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use:\n",
    "# 1.normal SVM with RBF\n",
    "# 2.Decision Tree\n",
    "# 3.Random Forest\n",
    "# 4.Do all of these with PCA/SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a18675c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45194274028629855"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_classifier = BernoulliNB()\n",
    "NB_classifier.fit(X,y)\n",
    "NB_classifier.score(X_v,y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7255e6b5-451b-4d2b-87fe-7d203a36c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimentionality reduction using SVD\n",
    "# feature lenght of 130 out of total 214 captures 95.3% of the energy of original data\n",
    "x_compressed = csr_matrix(X)\n",
    "x_test_compressed = csr_matrix(X_v)\n",
    "svd = TruncatedSVD(n_components=130)\n",
    "svd.fit(x_compressed)\n",
    "X_reduced = svd.transform(x_compressed)\n",
    "X_test_reduced = svd.transform(x_test_compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3410cc3f-bcda-4800-9648-65590889ff73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7080, 130)\n",
      "(489, 130)\n"
     ]
    }
   ],
   "source": [
    "print(X_reduced.shape)\n",
    "print(X_test_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "508ee6b8-17aa-4811-ba10-2f74d8c7019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # decision tree on reduced data\n",
    "# k_val = []\n",
    "# t_acc = []\n",
    "# v_acc = []\n",
    "# for depth in np.arange(1,11,1):\n",
    "#     k_val.append(depth)\n",
    "#     DT_classifier = DecisionTreeClassifier(max_depth=depth)\n",
    "#     DT_classifier.fit(X_reduced,y)\n",
    "#     t_acc.append(DT_classifier.score(X_reduced,y))\n",
    "#     v_acc.append(DT_classifier.score(X_test_reduced,y_v))\n",
    "\n",
    "# plt.plot(k_val, t_acc)\n",
    "# plt.plot(k_val, v_acc)\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61350517-7512-4867-b55e-67f6faac24f8",
   "metadata": {},
   "source": [
    "<h3>Approach 3: Creating encoding using deep learning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8717cb75-6130-4c9a-b97f-9af66968f81c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f9c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c85e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d106b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1248285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6cf1df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8956b2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed38cca6-9bb8-4437-837c-6f08c2f217b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebc0cc1-8558-40b2-93e3-fa5734a93fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7594ae-72f9-48bd-ac8b-06a1628a07c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0fdbbf30-27c4-47db-adb3-204b8392b1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "[0 1 1 ... 1 1 0]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[1 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0\n",
      " 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1 1\n",
      " 1 0 0 0 0 1 1 1 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0\n",
      " 0 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 0 0\n",
      " 0 1 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0\n",
      " 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0\n",
      " 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1\n",
      " 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0\n",
      " 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 1 0\n",
      " 0 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 1 0 1\n",
      " 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1\n",
      " 1 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1\n",
      " 1 1 1 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)\n",
    "print(X_v)\n",
    "print(y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e590975-8bb3-404a-9f2b-cbe8a3bdb319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ğŸ˜›ğŸ›ğŸ˜»ğŸ˜‘ğŸ˜£ğŸ™ ğŸ™¯ğŸš¼ğŸ˜’ğŸ™¼ğŸ˜‘ğŸ™¯ğŸ˜£', 0]\n",
      "['ğŸ›ğŸ˜‘ğŸ˜ªğŸ˜›ğŸš¼ğŸ™¯ğŸ˜£ğŸš…ğŸ˜‘ğŸ™¯ğŸ˜¹ğŸ˜£ğŸ™¼', 0]\n",
      "['ğŸ˜›ğŸ™¯ğŸ˜‘ğŸš¡ğŸ˜£ğŸš¼ğŸ›ğŸ™²ğŸ˜£ğŸ™¯ğŸ›‘ğŸ˜‘ğŸ™¼', 0]\n",
      "['ğŸ˜›ğŸš¼ğŸ›ğŸ™ğŸ˜£ğŸ™¯ğŸ˜‘ğŸ™ªğŸ˜‘ğŸ™¼ğŸ›†ğŸ˜£ğŸ™¯', 1]\n",
      "['ğŸ›ğŸšŸğŸš¼ğŸ˜›ğŸ™‹ğŸ˜‘ğŸ˜£ğŸ™¯ğŸ˜¹ğŸ™¯ğŸ˜‘ğŸ˜£ğŸ™¼', 1]\n",
      "['ğŸ˜‘ğŸ˜£ğŸš§ğŸ˜›ğŸšœğŸš¼ğŸ™¯ğŸ›ğŸ™¼ğŸ˜£ğŸ˜‘ğŸ™•ğŸ™¯', 1]\n",
      "['ğŸ˜£ğŸ˜‘ğŸ™¯ğŸš¼ğŸ›ğŸš¥ğŸ˜¬ğŸ˜›ğŸ˜£ğŸš„ğŸ˜‘ğŸ™¼ğŸ™¯', 0]\n",
      "['ğŸš¡ğŸš¼ğŸ˜‘ğŸ›ğŸš”ğŸ™¯ğŸ˜›ğŸ˜£ğŸ˜‘ğŸ™¯ğŸ›“ğŸ™¼ğŸ˜£', 0]\n",
      "['ğŸ›ğŸ˜›ğŸ›œğŸ˜‘ğŸš¼ğŸ˜šğŸ˜£ğŸ™¯ğŸ˜£ğŸ˜‘ğŸ™¯ğŸš ğŸ™¼', 0]\n",
      "['ğŸ™¯ğŸ˜‘ğŸ™·ğŸ›ğŸš¼ğŸ˜£ğŸ˜›ğŸ˜ğŸ˜¿ğŸ™¯ğŸ™¼ğŸ˜‘ğŸ˜£', 1]\n",
      "['ğŸ˜£ğŸ™¯ğŸ›ğŸ˜‘ğŸ˜›ğŸš¼ğŸ™šğŸ˜ğŸ™¯ğŸ™¼ğŸ˜£ğŸ˜‘ğŸ˜¸', 0]\n",
      "['ğŸ˜›ğŸ˜¯ğŸš¼ğŸ™¯ğŸ˜‘ğŸ›ğŸ˜»ğŸ˜£ğŸ™¼ğŸ™¯ğŸ˜¹ğŸ˜‘ğŸ˜£', 1]\n",
      "['ğŸ˜‘ğŸ™¯ğŸ˜›ğŸ›ğŸš¼ğŸ™’ğŸš™ğŸ˜£ğŸ™¯ğŸ˜£ğŸ˜‘ğŸ™¼ğŸ˜¬', 1]\n",
      "['ğŸ˜¿ğŸ˜£ğŸš¼ğŸš´ğŸ˜›ğŸ˜‘ğŸ™¯ğŸ›ğŸ˜£ğŸ™¯ğŸ˜‘ğŸ˜´ğŸ™¼', 1]\n",
      "['ğŸ˜›ğŸ›ğŸš¼ğŸš‚ğŸ™¯ğŸ˜¦ğŸ˜£ğŸ˜‘ğŸ™¯ğŸ˜‘ğŸ˜£ğŸ™¼ğŸ™¨', 1]\n",
      "['ğŸ›ğŸš¼ğŸ™¯ğŸ›ğŸ˜‘ğŸ˜‰ğŸ˜›ğŸ˜£ğŸ™’ğŸ˜£ğŸ™¼ğŸ˜‘ğŸ™¯', 0]\n",
      "['ğŸ˜£ğŸ™¯ğŸ˜µğŸ˜‘ğŸ˜›ğŸšƒğŸš¼ğŸ›ğŸ˜£ğŸ™¯ğŸšœğŸ™¼ğŸ˜‘', 0]\n",
      "['ğŸ˜›ğŸ˜‘ğŸ™¯ğŸš¼ğŸ›†ğŸ›ğŸ˜˜ğŸ˜£ğŸ˜£ğŸ˜ŠğŸ™¼ğŸ˜‘ğŸ™¯', 0]\n",
      "['ğŸšŸğŸ˜£ğŸ˜‘ğŸ›ğŸ˜ŒğŸš¼ğŸ˜›ğŸ™¯ğŸ™¯ğŸ˜£ğŸ˜‘ğŸ˜¿ğŸ™¼', 1]\n",
      "['ğŸ˜›ğŸš¼ğŸ˜‘ğŸ˜£ğŸ™§ğŸ›ğŸ™¯ğŸ˜‰ğŸšğŸ˜£ğŸ˜‘ğŸ™¯ğŸ™¼', 0]\n",
      "['ğŸ›“ğŸ›ğŸ˜£ğŸš¼ğŸ™¯ğŸš¥ğŸ˜‘ğŸ˜›ğŸ˜¢ğŸ˜£ğŸ™¯ğŸ˜‘ğŸ™¼', 1]\n",
      "['ğŸ˜£ğŸ˜‘ğŸšµğŸ˜›ğŸš¼ğŸ›ğŸ™¯ğŸ˜ŠğŸ™¼ğŸ˜£ğŸ™¯ğŸ˜‘ğŸ˜©', 0]\n",
      "['ğŸ›ğŸ™¯ğŸ˜›ğŸš¼ğŸ˜£ğŸ˜¬ğŸ˜ ğŸ˜‘ğŸ™¯ğŸ™¼ğŸ˜£ğŸ˜‘ğŸ›¡', 0]\n",
      "['ğŸ›ğŸ™¯ğŸšœğŸ˜£ğŸš¼ğŸ˜‘ğŸ˜°ğŸ˜›ğŸ˜‘ğŸ™¯ğŸšğŸ™¼ğŸ˜£', 1]\n",
      "['ğŸš¼ğŸ˜›ğŸ™¯ğŸ˜£ğŸš—ğŸ›ğŸ™¸ğŸ˜‘ğŸ˜£ğŸ™¼ğŸ™¯ğŸšŒğŸ˜‘', 1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    print([train_emoticon_X[i],train_emoticon_Y[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6816140-1e41-47bc-92e8-eac7a95c8cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_emoticon_X[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eacefd45-1ace-4433-a47d-713143a8cc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436029161998574100559715"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(train_emoticon_X[0][9].encode(\"unicode_escape\").hex(),16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ac1909c-7776-44ea-8888-eda564bd32b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[436029161998574100558178, 436029161998574100571184, 436029161998574100558690, 436029161998574100558129, 436029161998574100558387, 436029161998574100559408, 436029161998574100559462, 436029161998574100570723, 436029161998574100558130, 436029161998574100559715, 436029161998574100558129, 436029161998574100559462, 436029161998574100558387]\n"
     ]
    }
   ],
   "source": [
    "arr = to_unicode_decimal_array(train_emoticon_X[0])\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32339665-4422-43c8-a15c-706768c05e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n",
      "{'ğŸš£', 'ğŸš„', 'ğŸ™±', 'ğŸ˜¸', 'ğŸ™„', '\\U0001f6d8', 'ğŸ™”', 'ğŸš†', 'ğŸš“', 'ğŸš²', 'ğŸ™¯', 'ğŸš­', 'ğŸš¼', 'ğŸ™Š', 'ğŸ˜­', 'ğŸ›†', 'ğŸš¯', 'ğŸ™ ', 'ğŸšƒ', 'ğŸ™', 'ğŸ™Ÿ', 'ğŸ™…', 'ğŸš€', 'ğŸ˜’', 'ğŸ˜', 'ğŸ˜Š', 'ğŸ™®', 'ğŸš¾', 'ğŸš¶', 'ğŸ™š', '\\U0001f6dc', 'ğŸš', 'ğŸ˜²', 'ğŸ›', 'ğŸ™ƒ', '\\U0001f6d9', 'ğŸš', 'ğŸ˜£', 'ğŸ˜¦', 'ğŸ›', 'ğŸ™¶', 'ğŸš¥', 'ğŸ›…', 'ğŸšŒ', 'ğŸšœ', 'ğŸ™©', 'ğŸ™ˆ', 'ğŸ›“', 'ğŸ›', 'ğŸ˜§', 'ğŸ›', 'ğŸ™‰', 'ğŸšµ', 'ğŸ˜¨', 'ğŸ›ˆ', 'ğŸš•', 'ğŸ›€', 'ğŸ™¢', 'ğŸš¡', 'ğŸ˜„', 'ğŸ›•', 'ğŸš', 'ğŸ˜´', 'ğŸ˜±', 'ğŸ™—', 'ğŸ˜µ', 'ğŸ™¸', '\\U0001f6de', 'ğŸ™¾', 'ğŸ›‹', 'ğŸ™£', 'ğŸšŸ', 'ğŸš½', 'ğŸ˜½', 'ğŸ™', 'ğŸ›’', 'ğŸ˜‡', 'ğŸ˜…', 'ğŸ˜“', 'ğŸ™«', 'ğŸ˜˜', 'ğŸš¹', 'ğŸ˜—', 'ğŸ›‡', 'ğŸ˜¶', 'ğŸš‰', 'ğŸš', 'ğŸš', 'ğŸ™³', 'ğŸš®', 'ğŸ›‘', 'ğŸ˜¬', 'ğŸ˜›', 'ğŸš‡', 'ğŸ™Œ', 'ğŸ™‘', 'ğŸ™§', 'ğŸ™œ', 'ğŸ™¬', 'ğŸš˜', 'ğŸš–', 'ğŸ˜¢', 'ğŸ˜¥', 'ğŸ˜', 'ğŸ™', 'ğŸš±', 'ğŸš…', 'ğŸ™‡', 'ğŸ™›', 'ğŸ™¦', 'ğŸš·', 'ğŸ˜«', 'ğŸ›‚', 'ğŸš', 'ğŸš ', 'ğŸ˜¤', 'ğŸ˜¿', 'ğŸš¨', 'ğŸ™¹', 'ğŸ™¼', 'ğŸšš', 'ğŸ˜€', 'ğŸš©', 'ğŸ™¨', 'ğŸ™•', 'ğŸ™‹', 'ğŸ™°', 'ğŸ˜', 'ğŸ˜º', 'ğŸ˜»', 'ğŸ™»', 'ğŸš¿', 'ğŸ™€', 'ğŸ›¡', 'ğŸš›', 'ğŸš¸', 'ğŸ˜‰', 'ğŸ›‰', 'ğŸ˜†', 'ğŸš”', 'ğŸ˜œ', 'ğŸ˜¯', 'ğŸ˜ ', 'ğŸšˆ', 'ğŸ›Œ', 'ğŸ˜©', 'ğŸ˜ª', 'ğŸš‚', 'ğŸ˜Ÿ', 'ğŸš‘', 'ğŸ˜¾', 'ğŸš™', 'ğŸ›”', 'ğŸ™²', 'ğŸ˜‘', 'ğŸ˜®', 'ğŸš‹', 'ğŸ˜ƒ', 'ğŸ™†', 'ğŸ˜‚', 'ğŸ›—', 'ğŸ™', 'ğŸ›Š', 'ğŸ™˜', '\\U0001f6dd', 'ğŸ™™', 'ğŸ™´', '\\U0001f6db', 'ğŸ˜', 'ğŸ˜”', 'ğŸ˜°', 'ğŸ˜™', 'ğŸ™', 'ğŸ›„', 'ğŸš', 'ğŸ™', 'ğŸ˜¡', 'ğŸ™·', 'ğŸ˜Œ', '\\U0001f6df', 'ğŸ›', 'ğŸš—', 'ğŸ™¥', 'ğŸš§', 'ğŸš¢', 'ğŸš³', 'ğŸ›–', 'ğŸš’', 'ğŸš´', 'ğŸšª', 'ğŸ˜•', 'ğŸ˜', 'ğŸ™ª', 'ğŸ˜–', 'ğŸš°', 'ğŸ™½', 'ğŸ˜‹', 'ğŸ˜·', 'ğŸ˜š', 'ğŸ˜³', 'ğŸ˜', 'ğŸ˜', 'ğŸ™¤', 'ğŸš«', 'ğŸ˜¼', 'ğŸ™’', 'ğŸšº', 'ğŸš¦', 'ğŸš¤', 'ğŸ˜¹', 'ğŸ™–', 'ğŸ™“', 'ğŸ™¿', 'ğŸšŠ'}\n"
     ]
    }
   ],
   "source": [
    "print(len(emozi_set))\n",
    "print(emozi_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "952738ba-696c-4510-b122-98a1e3921c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(len(emozi_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52f909e4-a7e1-4f5c-a4e4-34392d902c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(converted_dataset[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "267f5e0f-13a4-484b-98ef-4276c17480c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "7080\n"
     ]
    }
   ],
   "source": [
    "print(X_v)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8412079c-e599-4648-8400-8fed244717b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(converted_validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5054581e-54d3-4906-a11c-c97535e83544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
