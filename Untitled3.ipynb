{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3aff75c-9d32-4cdc-a43b-030484534dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "Accuracy: 0.9795501022494888\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.9795501022494888\n",
      "\n",
      "SVM Results:\n",
      "Accuracy: 0.9979550102249489\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "train = np.load(\"D:\\\\MS IIT Kanpur\\\\CS771ML\\\\mini-project-1\\\\mini-project-1\\\\datasets\\\\train\\\\train_feature.npz\")\n",
    "valid=np.load(\"D:\\\\MS IIT Kanpur\\\\CS771ML\\\\mini-project-1\\\\mini-project-1\\\\datasets\\\\valid\\\\valid_feature.npz\")\n",
    "\n",
    "X_train = np.array(train['features'].tolist())\n",
    "y_train = np.array(train['label'])\n",
    "X_valid = np.array(valid['features'].tolist())\n",
    "y_valid = np.array(valid['label'])\n",
    "\n",
    "# flattening\n",
    "X__train_flattened = X_train.reshape(X_train.shape[0], -1)\n",
    "X__valid_flattened = X_valid.reshape(X_valid.shape[0], -1)\n",
    "\n",
    "X_train=X__train_flattened\n",
    "X_test=X__valid_flattened\n",
    "y_test=y_valid\n",
    "\n",
    "# Step 1: Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 2: Dimensionality Reduction using PCA\n",
    "pca = PCA(n_components=75)  # Choose the number of components based on explained variance\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Step 3: Classification using Logistic Regression and Random Forest\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=120,random_state=42)\n",
    "log_reg.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predictions and evaluation for Logistic Regression\n",
    "y_pred_log_reg = log_reg.predict(X_test_pca)\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predictions and evaluation for Random Forest\n",
    "y_pred_rf = rf_clf.predict(X_test_pca)\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "\n",
    "\n",
    "svm_clf = SVC(C=0.6,kernel=\"rbf\",random_state= 42)\n",
    "svm_clf.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predictions and evaluation for SVM\n",
    "y_pred_svm = svm_clf.predict(X_test_pca)\n",
    "print(\"\\nSVM Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf2ea34-8b2a-44ba-99c1-fb9dfc66f7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size =  100 %\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_1_1/embedding_1_1/GatherV2 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\puspe\\AppData\\Local\\Temp\\ipykernel_21756\\3732513486.py\", line 84, in <module>\n\n  File \"C:\\Users\\puspe\\AppData\\Local\\Temp\\ipykernel_21756\\3732513486.py\", line 70, in LSTM\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 51, in train_step\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 901, in __call__\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 212, in call\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 175, in call\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 560, in call\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 901, in __call__\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 140, in call\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 4918, in take\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 1967, in take\n\nindices[17,14] = 16 is not in [0, 13)\n\t [[{{node sequential_1_1/embedding_1_1/GatherV2}}]] [Op:__inference_one_step_on_iterator_8126]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 84\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(i\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset size = \u001b[39m\u001b[38;5;124m\"\u001b[39m,i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 84\u001b[0m     acc\u001b[38;5;241m.\u001b[39mappend((i,LSTM(X_train_pca,y_train,X_test_pca,y_test)))\n\u001b[0;32m     85\u001b[0m     i\u001b[38;5;241m=\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(acc) \n",
      "Cell \u001b[1;32mIn[7], line 70\u001b[0m, in \u001b[0;36mLSTM\u001b[1;34m(X_train_pca, y_train, X_test_pca, y_test)\u001b[0m\n\u001b[0;32m     65\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.004\u001b[39m), \n\u001b[0;32m     66\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     67\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Train the model (verbose=0 to suppress training output)\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test), verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m     73\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential_1_1/embedding_1_1/GatherV2 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\puspe\\AppData\\Local\\Temp\\ipykernel_21756\\3732513486.py\", line 84, in <module>\n\n  File \"C:\\Users\\puspe\\AppData\\Local\\Temp\\ipykernel_21756\\3732513486.py\", line 70, in LSTM\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 51, in train_step\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 901, in __call__\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 212, in call\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 175, in call\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 560, in call\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 901, in __call__\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 140, in call\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 4918, in take\n\n  File \"C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 1967, in take\n\nindices[17,14] = 16 is not in [0, 13)\n\t [[{{node sequential_1_1/embedding_1_1/GatherV2}}]] [Op:__inference_one_step_on_iterator_8126]"
     ]
    }
   ],
   "source": [
    "def LSTM(X_train_pca,y_train,X_test_pca,y_test):\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization, Attention\n",
    "    from tensorflow.keras import layers\n",
    "        \n",
    "    # Generate a random dataset\n",
    "    # X_train: (7080, 50) for training, X_test: (489, 50) for testing\n",
    "    # In real applications, replace this with your actual dataset\n",
    "    \n",
    "    # Assuming that input values are digits (0-9)\n",
    "    #dataset=int(percent*7080)\n",
    "    # # Generate random dataset\n",
    "    # np.random.seed(42)  # For reproducibility\n",
    "    # X = np.random.rand(1000, 50)  # 1000 samples, 50 features\n",
    "    # y = np.random.randint(0, 2, 1000)  # Binary target (0 or 1)\n",
    "    #print(type(train_seq_X[0]))\n",
    "    # Split dataset into training and testing sets\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    #X_train=np.array([1,2,3])\n",
    "    #y_train=np.array([1])\n",
    "    X_train=np.array(X_train_pca)\n",
    "    #print(type(X_train[0][0]))\n",
    "    #print(X_train[0:5])\n",
    "    y_train=np.array(y_train)\n",
    "    X_test=np.array(X_test_pca)\n",
    "    y_test=np.array(y_test)\n",
    "    \n",
    "    # Reshape input for LSTM - LSTM expects (samples, timesteps, features)\n",
    "    # Each sequence has 50 timesteps and 1 feature per timestep\n",
    "    #X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    #X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 1. Add an Embedding layer (214 possible emojis, mapped to a dense vector of size 10)\n",
    "    embedding_dim = 32\n",
    "    model.add(Embedding(input_dim=13, output_dim=embedding_dim, input_length=75))\n",
    "    \n",
    "    # 2. LSTM layer with 30 units\n",
    "    model.add(LSTM(32,return_sequences=False))\n",
    "    \n",
    "    # 3. Dropout layer to prevent overfitting (0.3 dropout)\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # 4. Batch Normalization layer for stable learning\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # 5. Dense layer with 15 units (ReLU activation)\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    \n",
    "    # 6. Another Dropout layer to further regularize\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # 7. Dense layer with 8 units (ReLU activation)\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    \n",
    "    # 8. Final output layer for binary classification (1 unit, sigmoid activation)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.004), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model (verbose=0 to suppress training output)\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"LSTM Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Model Summary\n",
    "    if percent==1:\n",
    "        model.summary()\n",
    "    return accuracy\n",
    "acc=[]\n",
    "i=1\n",
    "while(i<=1):\n",
    "    print(\"dataset size = \",i*100,'%')\n",
    "    acc.append((i,LSTM(X_train_pca,y_train,X_test_pca,y_test)))\n",
    "    i=i+0.2\n",
    "print(acc) \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(*zip(*acc))\n",
    "plt.ylim(0, 1.25)\n",
    "plt.title('Dataset 3 - Multilayer Neural Network')\n",
    "plt.xlabel('Percentage Dataset')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1fb3b7b-0d77-441c-8bf8-3f4ee1803ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7080, 75)\n",
      "(489, 75)\n",
      "(489,)\n",
      "(7080,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pca.shape)\n",
    "print(X_test_pca.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "098bae41-057b-42e0-bd5d-fc9d6957037f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size =  100 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.4994 - loss: 0.7735 - val_accuracy: 0.4847 - val_loss: 0.6968\n",
      "Epoch 2/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.4998 - loss: 0.6994 - val_accuracy: 0.5031 - val_loss: 0.6965\n",
      "Epoch 3/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.4969 - loss: 0.6976 - val_accuracy: 0.5031 - val_loss: 0.6944\n",
      "Epoch 4/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5153 - loss: 0.6944 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
      "Epoch 5/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5009 - loss: 0.6967 - val_accuracy: 0.5112 - val_loss: 0.6934\n",
      "Epoch 6/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5124 - loss: 0.6926 - val_accuracy: 0.5276 - val_loss: 0.6938\n",
      "Epoch 7/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5185 - loss: 0.6933 - val_accuracy: 0.5010 - val_loss: 0.6933\n",
      "Epoch 8/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.5106 - loss: 0.6956 - val_accuracy: 0.5297 - val_loss: 0.6925\n",
      "Epoch 9/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.5047 - loss: 0.6935 - val_accuracy: 0.5337 - val_loss: 0.6908\n",
      "Epoch 10/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.5167 - loss: 0.6937 - val_accuracy: 0.5276 - val_loss: 0.6920\n",
      "Epoch 11/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5098 - loss: 0.6926 - val_accuracy: 0.5440 - val_loss: 0.6906\n",
      "Epoch 12/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.5076 - loss: 0.6935 - val_accuracy: 0.5665 - val_loss: 0.6906\n",
      "Epoch 13/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5218 - loss: 0.6912 - val_accuracy: 0.5501 - val_loss: 0.6886\n",
      "Epoch 14/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.5171 - loss: 0.6937 - val_accuracy: 0.5562 - val_loss: 0.6896\n",
      "Epoch 15/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.5188 - loss: 0.6926 - val_accuracy: 0.5419 - val_loss: 0.6905\n",
      "Epoch 16/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.5292 - loss: 0.6907 - val_accuracy: 0.5542 - val_loss: 0.6893\n",
      "Epoch 17/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.5182 - loss: 0.6915 - val_accuracy: 0.5297 - val_loss: 0.6889\n",
      "Epoch 18/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.5194 - loss: 0.6918 - val_accuracy: 0.5399 - val_loss: 0.6887\n",
      "Epoch 19/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.5142 - loss: 0.6922 - val_accuracy: 0.5215 - val_loss: 0.6904\n",
      "Epoch 20/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.5154 - loss: 0.6926 - val_accuracy: 0.5399 - val_loss: 0.6900\n",
      "Epoch 21/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5102 - loss: 0.6923 - val_accuracy: 0.5317 - val_loss: 0.6886\n",
      "Epoch 22/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.5067 - loss: 0.6936 - val_accuracy: 0.5297 - val_loss: 0.6897\n",
      "Epoch 23/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5157 - loss: 0.6926 - val_accuracy: 0.5317 - val_loss: 0.6897\n",
      "Epoch 24/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.5255 - loss: 0.6915 - val_accuracy: 0.5297 - val_loss: 0.6893\n",
      "Epoch 25/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5319 - loss: 0.6903 - val_accuracy: 0.5481 - val_loss: 0.6887\n",
      "Epoch 26/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5316 - loss: 0.6902 - val_accuracy: 0.5521 - val_loss: 0.6891\n",
      "Epoch 27/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.5134 - loss: 0.6920 - val_accuracy: 0.5378 - val_loss: 0.6873\n",
      "Epoch 28/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.5178 - loss: 0.6914 - val_accuracy: 0.5337 - val_loss: 0.6874\n",
      "Epoch 29/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.5250 - loss: 0.6887 - val_accuracy: 0.5440 - val_loss: 0.6881\n",
      "Epoch 30/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.5245 - loss: 0.6910 - val_accuracy: 0.5256 - val_loss: 0.6888\n",
      "Epoch 31/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.5240 - loss: 0.6906 - val_accuracy: 0.5460 - val_loss: 0.6886\n",
      "Epoch 32/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.5310 - loss: 0.6893 - val_accuracy: 0.5133 - val_loss: 0.6896\n",
      "Epoch 33/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5387 - loss: 0.6895 - val_accuracy: 0.5521 - val_loss: 0.6883\n",
      "Epoch 34/50\n",
      "\u001b[1m 41/111\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5263 - loss: 0.6888"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset size = \u001b[39m\u001b[38;5;124m\"\u001b[39m, i \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m     acc\u001b[38;5;241m.\u001b[39mappend((i, LSTM_model(X_train_pca, y_train, X_test_pca, y_test)))\n\u001b[0;32m     62\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Plot the results\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 49\u001b[0m, in \u001b[0;36mLSTM_model\u001b[1;34m(X_train_pca, y_train, X_test_pca, y_test)\u001b[0m\n\u001b[0;32m     44\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0008\u001b[39m), \n\u001b[0;32m     45\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     46\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test), verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m     52\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1553\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1554\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1555\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1556\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1557\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1558\u001b[0m   )\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def LSTM_model(X_train_pca, y_train, X_test_pca, y_test):\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "    \n",
    "    # Convert the inputs to NumPy arrays\n",
    "    X_train = np.array(X_train_pca)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test_pca)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Reshape input for LSTM - LSTM expects (samples, timesteps, features)\n",
    "    # Here, we'll reshape to (samples, timesteps, features) where timesteps = 75 and features = 1\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 1. LSTM layer with 32 units\n",
    "    model.add(LSTM(32, return_sequences=False, input_shape=(75, 1)))\n",
    "    \n",
    "    # 2. Dropout layer to prevent overfitting (0.5 dropout)\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # 3. Batch Normalization layer for stable learning\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # 4. Dense layer with 15 units (ReLU activation)\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    \n",
    "    # 5. Another Dropout layer to further regularize\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # 6. Dense layer with 15 units (ReLU activation)\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    \n",
    "    # 7. Final output layer for binary classification (1 unit, sigmoid activation)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0008), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test), verbose=1)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"LSTM Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Example usage\n",
    "acc = []\n",
    "i = 1\n",
    "while i <= 1:\n",
    "    print(\"Dataset size = \", i * 100, '%')\n",
    "    acc.append((i, LSTM_model(X_train_pca, y_train, X_test_pca, y_test)))\n",
    "    i += 0.2\n",
    "\n",
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(*zip(*acc))\n",
    "plt.ylim(0, 1.25)\n",
    "plt.title('Dataset 3 - LSTM Performance')\n",
    "plt.xlabel('Percentage Dataset')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2f4a8f2-24f2-4a90-af7e-5ab36436bb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size =  100 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7794 - loss: 0.4223 - val_accuracy: 0.9652 - val_loss: 0.0975\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9344 - loss: 0.1631 - val_accuracy: 0.9673 - val_loss: 0.0861\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9467 - loss: 0.1335 - val_accuracy: 0.9857 - val_loss: 0.0506\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1065 - val_accuracy: 0.9816 - val_loss: 0.0528\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1057 - val_accuracy: 0.9857 - val_loss: 0.0402\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.1041 - val_accuracy: 0.9898 - val_loss: 0.0474\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.0932 - val_accuracy: 0.9918 - val_loss: 0.0456\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9683 - loss: 0.0764 - val_accuracy: 0.9918 - val_loss: 0.0328\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.0692 - val_accuracy: 0.9939 - val_loss: 0.0349\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9701 - loss: 0.0799 - val_accuracy: 0.9918 - val_loss: 0.0315\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9671 - loss: 0.0846 - val_accuracy: 0.9898 - val_loss: 0.0330\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9696 - loss: 0.0774 - val_accuracy: 0.9877 - val_loss: 0.0282\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9751 - loss: 0.0741 - val_accuracy: 0.9918 - val_loss: 0.0357\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9725 - loss: 0.0722 - val_accuracy: 0.9898 - val_loss: 0.0330\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.0658 - val_accuracy: 0.9857 - val_loss: 0.0385\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9752 - loss: 0.0681 - val_accuracy: 0.9918 - val_loss: 0.0303\n",
      "Epoch 17/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9789 - loss: 0.0565 - val_accuracy: 0.9877 - val_loss: 0.0359\n",
      "Epoch 18/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9732 - loss: 0.0743 - val_accuracy: 0.9918 - val_loss: 0.0341\n",
      "Epoch 19/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.0493 - val_accuracy: 0.9898 - val_loss: 0.0372\n",
      "Epoch 20/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.0564 - val_accuracy: 0.9918 - val_loss: 0.0376\n",
      "Epoch 21/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.0571 - val_accuracy: 0.9918 - val_loss: 0.0311\n",
      "Epoch 22/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9795 - loss: 0.0510 - val_accuracy: 0.9918 - val_loss: 0.0372\n",
      "Epoch 23/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.0577 - val_accuracy: 0.9857 - val_loss: 0.0356\n",
      "Epoch 24/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9741 - loss: 0.0599 - val_accuracy: 0.9898 - val_loss: 0.0311\n",
      "Epoch 25/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9836 - loss: 0.0464 - val_accuracy: 0.9939 - val_loss: 0.0331\n",
      "Epoch 26/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9762 - loss: 0.0638 - val_accuracy: 0.9918 - val_loss: 0.0274\n",
      "Epoch 27/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9827 - loss: 0.0521 - val_accuracy: 0.9918 - val_loss: 0.0420\n",
      "Epoch 28/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9775 - loss: 0.0552 - val_accuracy: 0.9918 - val_loss: 0.0329\n",
      "Epoch 29/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9791 - loss: 0.0533 - val_accuracy: 0.9877 - val_loss: 0.0323\n",
      "Epoch 30/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0436 - val_accuracy: 0.9877 - val_loss: 0.0306\n",
      "Epoch 31/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.0565 - val_accuracy: 0.9939 - val_loss: 0.0296\n",
      "Epoch 32/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9820 - loss: 0.0462 - val_accuracy: 0.9836 - val_loss: 0.0307\n",
      "Epoch 33/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.0459 - val_accuracy: 0.9857 - val_loss: 0.0308\n",
      "Epoch 34/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0492 - val_accuracy: 0.9898 - val_loss: 0.0371\n",
      "Epoch 35/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.0473 - val_accuracy: 0.9918 - val_loss: 0.0261\n",
      "Epoch 36/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.0419 - val_accuracy: 0.9857 - val_loss: 0.0377\n",
      "Epoch 37/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.0546 - val_accuracy: 0.9898 - val_loss: 0.0292\n",
      "Epoch 38/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9808 - loss: 0.0487 - val_accuracy: 0.9898 - val_loss: 0.0289\n",
      "Epoch 39/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.0524 - val_accuracy: 0.9857 - val_loss: 0.0327\n",
      "Epoch 40/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.0565 - val_accuracy: 0.9918 - val_loss: 0.0263\n",
      "Epoch 41/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.0439 - val_accuracy: 0.9918 - val_loss: 0.0305\n",
      "Epoch 42/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9858 - loss: 0.0419 - val_accuracy: 0.9918 - val_loss: 0.0298\n",
      "Epoch 43/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0375 - val_accuracy: 0.9898 - val_loss: 0.0271\n",
      "Epoch 44/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9865 - loss: 0.0424 - val_accuracy: 0.9898 - val_loss: 0.0346\n",
      "Epoch 45/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9876 - loss: 0.0372 - val_accuracy: 0.9939 - val_loss: 0.0317\n",
      "Epoch 46/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0468 - val_accuracy: 0.9918 - val_loss: 0.0247\n",
      "Epoch 47/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.0462 - val_accuracy: 0.9918 - val_loss: 0.0325\n",
      "Epoch 48/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9799 - loss: 0.0543 - val_accuracy: 0.9898 - val_loss: 0.0249\n",
      "Epoch 49/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9859 - loss: 0.0409 - val_accuracy: 0.9918 - val_loss: 0.0259\n",
      "Epoch 50/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0464 - val_accuracy: 0.9898 - val_loss: 0.0268\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0236 \n",
      "DNN Test Accuracy: 98.98%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def DNN_model(X_train_pca, y_train, X_test_pca, y_test):\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "    \n",
    "    # Convert the inputs to NumPy arrays\n",
    "    X_train = np.array(X_train_pca)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test_pca)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 1. First Dense layer with 128 units and ReLU activation\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    \n",
    "    # 2. Dropout layer to prevent overfitting (0.5 dropout)\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # 3. Batch Normalization for stable learning\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # 4. Second Dense layer with 64 units and ReLU activation\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    \n",
    "    # 5. Dropout layer to further regularize\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # 6. Third Dense layer with 32 units and ReLU activation\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    \n",
    "    # 7. Final output layer for binary classification (1 unit, sigmoid activation)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.004), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"DNN Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Example usage\n",
    "acc = []\n",
    "i = 1\n",
    "while i <= 1:\n",
    "    print(\"Dataset size = \", i * 100, '%')\n",
    "    acc.append((i, DNN_model(X_train_pca, y_train, X_test_pca, y_test)))\n",
    "    i += 0.2\n",
    "\n",
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(*zip(*acc))\n",
    "plt.ylim(0, 1.25)\n",
    "plt.title('Dataset 3 - DNN Performance')\n",
    "plt.xlabel('Percentage Dataset')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26b993db-414d-4ef1-ba0d-7f6319585633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size =  100 %\n",
      "Epoch 1/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.7906 - loss: 0.7945 - val_accuracy: 0.9755 - val_loss: 0.3937\n",
      "Epoch 2/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9411 - loss: 0.4591 - val_accuracy: 0.9796 - val_loss: 0.3401\n",
      "Epoch 3/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.3801 - val_accuracy: 0.9857 - val_loss: 0.2880\n",
      "Epoch 4/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9639 - loss: 0.3272 - val_accuracy: 0.9816 - val_loss: 0.2538\n",
      "Epoch 5/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9655 - loss: 0.2829 - val_accuracy: 0.9898 - val_loss: 0.2067\n",
      "Epoch 6/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9692 - loss: 0.2462 - val_accuracy: 0.9857 - val_loss: 0.1931\n",
      "Epoch 7/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9777 - loss: 0.2037 - val_accuracy: 0.9836 - val_loss: 0.1712\n",
      "Epoch 8/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9775 - loss: 0.1879 - val_accuracy: 0.9836 - val_loss: 0.1550\n",
      "Epoch 9/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.1642 - val_accuracy: 0.9836 - val_loss: 0.1341\n",
      "Epoch 10/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9819 - loss: 0.1478 - val_accuracy: 0.9898 - val_loss: 0.1226\n",
      "Epoch 11/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9836 - loss: 0.1395 - val_accuracy: 0.9857 - val_loss: 0.1187\n",
      "Epoch 12/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.1304 - val_accuracy: 0.9857 - val_loss: 0.1125\n",
      "Epoch 13/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9790 - loss: 0.1408 - val_accuracy: 0.9898 - val_loss: 0.1078\n",
      "Epoch 14/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.1306 - val_accuracy: 0.9898 - val_loss: 0.1048\n",
      "Epoch 15/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.1140 - val_accuracy: 0.9836 - val_loss: 0.1200\n",
      "Epoch 16/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9785 - loss: 0.1296 - val_accuracy: 0.9877 - val_loss: 0.1085\n",
      "Epoch 17/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.1064 - val_accuracy: 0.9918 - val_loss: 0.0931\n",
      "Epoch 18/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9836 - loss: 0.1148 - val_accuracy: 0.9939 - val_loss: 0.0955\n",
      "Epoch 19/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9878 - loss: 0.1040 - val_accuracy: 0.9836 - val_loss: 0.1018\n",
      "Epoch 20/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.1104 - val_accuracy: 0.9857 - val_loss: 0.0940\n",
      "Epoch 21/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.1070 - val_accuracy: 0.9836 - val_loss: 0.0944\n",
      "Epoch 22/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9873 - loss: 0.1038 - val_accuracy: 0.9877 - val_loss: 0.0958\n",
      "Epoch 23/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9853 - loss: 0.1046 - val_accuracy: 0.9877 - val_loss: 0.0858\n",
      "Epoch 24/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.1057 - val_accuracy: 0.9898 - val_loss: 0.0927\n",
      "Epoch 25/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.1053 - val_accuracy: 0.9898 - val_loss: 0.0895\n",
      "Epoch 26/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.1061 - val_accuracy: 0.9918 - val_loss: 0.0924\n",
      "Epoch 27/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9873 - loss: 0.0971 - val_accuracy: 0.9959 - val_loss: 0.0779\n",
      "Epoch 28/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.1055 - val_accuracy: 0.9857 - val_loss: 0.0960\n",
      "Epoch 29/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0993 - val_accuracy: 0.9939 - val_loss: 0.0896\n",
      "Epoch 30/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9870 - loss: 0.0988 - val_accuracy: 0.9939 - val_loss: 0.0809\n",
      "Epoch 31/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.1006 - val_accuracy: 0.9918 - val_loss: 0.0862\n",
      "Epoch 32/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9870 - loss: 0.1002 - val_accuracy: 0.9939 - val_loss: 0.0822\n",
      "Epoch 33/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0973 - val_accuracy: 0.9918 - val_loss: 0.0825\n",
      "Epoch 34/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.1057 - val_accuracy: 0.9918 - val_loss: 0.0837\n",
      "Epoch 35/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.1075 - val_accuracy: 0.9877 - val_loss: 0.0870\n",
      "Epoch 36/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0958 - val_accuracy: 0.9898 - val_loss: 0.0900\n",
      "Epoch 37/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0988 - val_accuracy: 0.9939 - val_loss: 0.0859\n",
      "Epoch 38/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9903 - loss: 0.0970 - val_accuracy: 0.9959 - val_loss: 0.0794\n",
      "Epoch 39/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0934 - val_accuracy: 0.9898 - val_loss: 0.0837\n",
      "Epoch 40/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0964 - val_accuracy: 0.9898 - val_loss: 0.0916\n",
      "Epoch 41/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0968 - val_accuracy: 0.9918 - val_loss: 0.0823\n",
      "Epoch 42/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0942 - val_accuracy: 0.9918 - val_loss: 0.0865\n",
      "Epoch 43/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9879 - loss: 0.0969 - val_accuracy: 0.9939 - val_loss: 0.0810\n",
      "Epoch 44/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.1006 - val_accuracy: 0.9898 - val_loss: 0.0824\n",
      "Epoch 45/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9880 - loss: 0.0938 - val_accuracy: 0.9877 - val_loss: 0.0839\n",
      "Epoch 46/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0954 - val_accuracy: 0.9959 - val_loss: 0.0835\n",
      "Epoch 47/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.0964 - val_accuracy: 0.9877 - val_loss: 0.0837\n",
      "Epoch 48/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0910 - val_accuracy: 0.9918 - val_loss: 0.0796\n",
      "Epoch 49/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9899 - loss: 0.0914 - val_accuracy: 0.9898 - val_loss: 0.0805\n",
      "Epoch 50/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0900 - val_accuracy: 0.9918 - val_loss: 0.0850\n",
      "Epoch 51/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0946 - val_accuracy: 0.9877 - val_loss: 0.0830\n",
      "Epoch 52/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9877 - loss: 0.0918 - val_accuracy: 0.9918 - val_loss: 0.0805\n",
      "Epoch 53/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9880 - loss: 0.0936 - val_accuracy: 0.9898 - val_loss: 0.0849\n",
      "Epoch 54/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0864 - val_accuracy: 0.9918 - val_loss: 0.0899\n",
      "Epoch 55/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9888 - loss: 0.0923 - val_accuracy: 0.9898 - val_loss: 0.0855\n",
      "Epoch 56/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.1016 - val_accuracy: 0.9857 - val_loss: 0.0847\n",
      "Epoch 57/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.1072 - val_accuracy: 0.9980 - val_loss: 0.0756\n",
      "Epoch 58/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0872 - val_accuracy: 0.9898 - val_loss: 0.0844\n",
      "Epoch 59/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0898 - val_accuracy: 0.9836 - val_loss: 0.0881\n",
      "Epoch 60/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0903 - val_accuracy: 0.9836 - val_loss: 0.0950\n",
      "Epoch 61/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.0899 - val_accuracy: 0.9877 - val_loss: 0.0959\n",
      "Epoch 62/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9888 - loss: 0.0874 - val_accuracy: 0.9939 - val_loss: 0.0911\n",
      "Epoch 63/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9888 - loss: 0.0912 - val_accuracy: 0.9877 - val_loss: 0.0882\n",
      "Epoch 64/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.0955 - val_accuracy: 0.9898 - val_loss: 0.0877\n",
      "Epoch 65/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9906 - loss: 0.0902 - val_accuracy: 0.9939 - val_loss: 0.0793\n",
      "Epoch 66/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0898 - val_accuracy: 0.9898 - val_loss: 0.0907\n",
      "Epoch 67/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.0962 - val_accuracy: 0.9898 - val_loss: 0.0847\n",
      "Epoch 68/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0930 - val_accuracy: 0.9918 - val_loss: 0.0818\n",
      "Epoch 69/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.0921 - val_accuracy: 0.9939 - val_loss: 0.0842\n",
      "Epoch 70/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0825 - val_accuracy: 0.9857 - val_loss: 0.0919\n",
      "Epoch 71/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9894 - loss: 0.0902 - val_accuracy: 0.9857 - val_loss: 0.0933\n",
      "Epoch 72/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9897 - loss: 0.0892 - val_accuracy: 0.9898 - val_loss: 0.0928\n",
      "Epoch 73/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0846 - val_accuracy: 0.9898 - val_loss: 0.0879\n",
      "Epoch 74/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0841 - val_accuracy: 0.9836 - val_loss: 0.0959\n",
      "Epoch 75/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0933 - val_accuracy: 0.9918 - val_loss: 0.0909\n",
      "Epoch 76/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9882 - loss: 0.0902 - val_accuracy: 0.9898 - val_loss: 0.0841\n",
      "Epoch 77/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9888 - loss: 0.0895 - val_accuracy: 0.9918 - val_loss: 0.0904\n",
      "Epoch 78/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9898 - loss: 0.0859 - val_accuracy: 0.9918 - val_loss: 0.0834\n",
      "Epoch 79/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.0981 - val_accuracy: 0.9939 - val_loss: 0.0797\n",
      "Epoch 80/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0913 - val_accuracy: 0.9857 - val_loss: 0.0870\n",
      "Epoch 81/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0943 - val_accuracy: 0.9918 - val_loss: 0.0775\n",
      "Epoch 82/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9878 - loss: 0.0951 - val_accuracy: 0.9877 - val_loss: 0.0919\n",
      "Epoch 83/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0831 - val_accuracy: 0.9959 - val_loss: 0.0756\n",
      "Epoch 84/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9906 - loss: 0.0870 - val_accuracy: 0.9918 - val_loss: 0.0826\n",
      "Epoch 85/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.1034 - val_accuracy: 0.9918 - val_loss: 0.0808\n",
      "Epoch 86/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.1021 - val_accuracy: 0.9939 - val_loss: 0.0790\n",
      "Epoch 87/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9880 - loss: 0.0951 - val_accuracy: 0.9939 - val_loss: 0.0776\n",
      "Epoch 88/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9893 - loss: 0.0903 - val_accuracy: 0.9918 - val_loss: 0.0852\n",
      "Epoch 89/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 0.0850 - val_accuracy: 0.9857 - val_loss: 0.0906\n",
      "Epoch 90/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0947 - val_accuracy: 0.9877 - val_loss: 0.0870\n",
      "Epoch 91/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9880 - loss: 0.0902 - val_accuracy: 0.9918 - val_loss: 0.0854\n",
      "Epoch 92/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.0941 - val_accuracy: 0.9918 - val_loss: 0.0829\n",
      "Epoch 93/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0882 - val_accuracy: 0.9877 - val_loss: 0.0882\n",
      "Epoch 94/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.1018 - val_accuracy: 0.9857 - val_loss: 0.0931\n",
      "Epoch 95/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9898 - loss: 0.0903 - val_accuracy: 0.9877 - val_loss: 0.0953\n",
      "Epoch 96/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0926 - val_accuracy: 0.9836 - val_loss: 0.1025\n",
      "Epoch 97/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0918 - val_accuracy: 0.9898 - val_loss: 0.0888\n",
      "Epoch 98/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0925 - val_accuracy: 0.9939 - val_loss: 0.0802\n",
      "Epoch 99/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9903 - loss: 0.0873 - val_accuracy: 0.9918 - val_loss: 0.0826\n",
      "Epoch 100/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0871 - val_accuracy: 0.9939 - val_loss: 0.0831\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0917 \n",
      "Improved DNN Test Accuracy: 99.39%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def improved_DNN_model(X_train_pca, y_train, X_test_pca, y_test):\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "    \n",
    "    # Convert the inputs to NumPy arrays\n",
    "    X_train = np.array(X_train_pca)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test_pca)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 1. First Dense layer with 256 units, ReLU activation, and L2 regularization\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001), input_shape=(X_train.shape[1],)))\n",
    "    \n",
    "    # 2. Dropout layer to prevent overfitting (0.4 dropout)\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # 3. Batch Normalization for stable learning\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # 4. Second Dense layer with 128 units and ReLU activation\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    \n",
    "    # 5. Dropout layer to further regularize (0.4 dropout)\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # 6. Third Dense layer with 64 units and ReLU activation\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    \n",
    "    # 7. Final output layer for binary classification (1 unit, sigmoid activation)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"Improved DNN Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Example usage\n",
    "acc = []\n",
    "i = 1\n",
    "while i <= 1:\n",
    "    print(\"Dataset size = \", i * 100, '%')\n",
    "    acc.append((i, improved_DNN_model(X_train_pca, y_train, X_test_pca, y_test)))\n",
    "    i += 0.2\n",
    "\n",
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(*zip(*acc))\n",
    "plt.ylim(0, 1.25)\n",
    "plt.title('Dataset 3 - Improved DNN Performance')\n",
    "plt.xlabel('Percentage Dataset')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "825651d7-5f5c-461f-a79d-843e7315d3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.5762 - loss: 0.7416 - val_accuracy: 0.8998 - val_loss: 0.3380 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.4047 - val_accuracy: 0.9530 - val_loss: 0.1521 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8915 - loss: 0.2490 - val_accuracy: 0.9652 - val_loss: 0.1100 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9224 - loss: 0.1904 - val_accuracy: 0.9734 - val_loss: 0.0859 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9174 - loss: 0.1973 - val_accuracy: 0.9755 - val_loss: 0.0780 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9487 - loss: 0.1429 - val_accuracy: 0.9673 - val_loss: 0.0711 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9481 - loss: 0.1376 - val_accuracy: 0.9836 - val_loss: 0.0573 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9620 - loss: 0.1048 - val_accuracy: 0.9836 - val_loss: 0.0549 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9630 - loss: 0.0989 - val_accuracy: 0.9857 - val_loss: 0.0432 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9654 - loss: 0.0965 - val_accuracy: 0.9898 - val_loss: 0.0364 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9659 - loss: 0.0887 - val_accuracy: 0.9877 - val_loss: 0.0383 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9725 - loss: 0.0777 - val_accuracy: 0.9898 - val_loss: 0.0352 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9744 - loss: 0.0754 - val_accuracy: 0.9898 - val_loss: 0.0279 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9680 - loss: 0.0819 - val_accuracy: 0.9898 - val_loss: 0.0289 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9769 - loss: 0.0597 - val_accuracy: 0.9918 - val_loss: 0.0333 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9717 - loss: 0.0755 - val_accuracy: 0.9918 - val_loss: 0.0274 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9775 - loss: 0.0665 - val_accuracy: 0.9959 - val_loss: 0.0286 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9736 - loss: 0.0726 - val_accuracy: 0.9918 - val_loss: 0.0287 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m210/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9765 - loss: 0.0689\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9766 - loss: 0.0687 - val_accuracy: 0.9877 - val_loss: 0.0304 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.0542 - val_accuracy: 0.9918 - val_loss: 0.0271 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9809 - loss: 0.0530 - val_accuracy: 0.9918 - val_loss: 0.0280 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9796 - loss: 0.0515 - val_accuracy: 0.9898 - val_loss: 0.0290 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.0450 - val_accuracy: 0.9918 - val_loss: 0.0211 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.0495 - val_accuracy: 0.9898 - val_loss: 0.0272 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9823 - loss: 0.0506 - val_accuracy: 0.9959 - val_loss: 0.0185 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9834 - loss: 0.0441 - val_accuracy: 0.9939 - val_loss: 0.0211 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9784 - loss: 0.0530 - val_accuracy: 0.9918 - val_loss: 0.0203 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m213/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.0511\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0508 - val_accuracy: 0.9898 - val_loss: 0.0213 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9835 - loss: 0.0453 - val_accuracy: 0.9898 - val_loss: 0.0237 - learning_rate: 2.5000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0339 - val_accuracy: 0.9898 - val_loss: 0.0248 - learning_rate: 2.5000e-04\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0178 \n",
      "Improved DNN Test Accuracy: 99.59%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Convert the inputs to NumPy arrays (if they are not already)\n",
    "X_train = np.array(X_train_pca)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test_pca)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Standardize the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Model definition\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer and first hidden layer\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Second hidden layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Third hidden layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Output layer for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=100, \n",
    "          batch_size=32, \n",
    "          validation_data=(X_test, y_test), \n",
    "          callbacks=[lr_scheduler, early_stopping], \n",
    "          verbose=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Improved DNN Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef4c21a-e919-4847-a5d9-b2f5e982b9ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, ReduceLROnPlateau\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Function to create a model\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.wrappers'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Function to create a model\n",
    "def create_model(learning_rate=0.001, dropout_rate=0.5, layers=1, units=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_shape=(X_train_pca.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        \n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_pca)\n",
    "X_test_scaled = scaler.transform(X_test_pca)\n",
    "\n",
    "# Early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\n",
    "\n",
    "# KerasClassifier wrapper for GridSearchCV\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.004],\n",
    "    'dropout_rate': [0.3, 0.5],\n",
    "    'layers': [1, 2],\n",
    "    'units': [32, 64]\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_result = grid.fit(X_train_scaled, y_train, validation_data=(X_test_scaled, y_test), \n",
    "                        epochs=100, batch_size=32, callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "# Best model and parameters\n",
    "best_model = grid_result.best_estimator_\n",
    "print(f\"Best parameters: {grid_result.best_params_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Improved DNN Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfd339e1-ea40-418b-8add-c8c4a8368c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\puspe\\anaconda3\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (69.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\puspe\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b98f9b2a-f9c1-4aed-96f5-f4d3ee138d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params: {'learning_rate': 0.001, 'dropout_rate': 0.3, 'layers': 1, 'units': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5414 - loss: 0.7615 - val_accuracy: 0.7867 - val_loss: 0.5258 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7694 - loss: 0.4899 - val_accuracy: 0.8905 - val_loss: 0.3508 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8753 - loss: 0.3361 - val_accuracy: 0.9287 - val_loss: 0.2481 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9172 - loss: 0.2371 - val_accuracy: 0.9569 - val_loss: 0.1864 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.1829 - val_accuracy: 0.9590 - val_loss: 0.1491 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.1452 - val_accuracy: 0.9668 - val_loss: 0.1251 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9546 - loss: 0.1274 - val_accuracy: 0.9696 - val_loss: 0.1060 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1154 - val_accuracy: 0.9703 - val_loss: 0.0951 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 0.0962 - val_accuracy: 0.9760 - val_loss: 0.0847 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9739 - loss: 0.0840 - val_accuracy: 0.9781 - val_loss: 0.0750 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9766 - loss: 0.0722 - val_accuracy: 0.9816 - val_loss: 0.0670 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9727 - loss: 0.0746 - val_accuracy: 0.9823 - val_loss: 0.0621 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9740 - loss: 0.0624 - val_accuracy: 0.9809 - val_loss: 0.0583 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9782 - loss: 0.0577 - val_accuracy: 0.9823 - val_loss: 0.0534 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9824 - loss: 0.0514 - val_accuracy: 0.9809 - val_loss: 0.0509 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9857 - loss: 0.0470 - val_accuracy: 0.9831 - val_loss: 0.0488 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9822 - loss: 0.0501 - val_accuracy: 0.9802 - val_loss: 0.0489 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0363 - val_accuracy: 0.9852 - val_loss: 0.0432 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0355 - val_accuracy: 0.9831 - val_loss: 0.0417 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9899 - loss: 0.0369 - val_accuracy: 0.9823 - val_loss: 0.0415 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9850 - loss: 0.0371 - val_accuracy: 0.9838 - val_loss: 0.0375 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0307 - val_accuracy: 0.9831 - val_loss: 0.0383 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0301 - val_accuracy: 0.9838 - val_loss: 0.0399 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0306 - val_accuracy: 0.9845 - val_loss: 0.0391 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9869 - loss: 0.0316 - val_accuracy: 0.9802 - val_loss: 0.0390 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0248 - val_accuracy: 0.9852 - val_loss: 0.0356 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0235 - val_accuracy: 0.9845 - val_loss: 0.0351 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0241 - val_accuracy: 0.9845 - val_loss: 0.0351 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.0260 - val_accuracy: 0.9845 - val_loss: 0.0343 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0230 - val_accuracy: 0.9838 - val_loss: 0.0353 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0198 - val_accuracy: 0.9887 - val_loss: 0.0319 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0169 - val_accuracy: 0.9866 - val_loss: 0.0318 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0197 - val_accuracy: 0.9852 - val_loss: 0.0332 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0239 - val_accuracy: 0.9845 - val_loss: 0.0321 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0209 - val_accuracy: 0.9859 - val_loss: 0.0327 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0175 - val_accuracy: 0.9838 - val_loss: 0.0330 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0169 - val_accuracy: 0.9852 - val_loss: 0.0316 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0177 - val_accuracy: 0.9908 - val_loss: 0.0270 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0128 - val_accuracy: 0.9852 - val_loss: 0.0327 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0148 - val_accuracy: 0.9880 - val_loss: 0.0305 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0175 - val_accuracy: 0.9894 - val_loss: 0.0284 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0154 - val_accuracy: 0.9873 - val_loss: 0.0287 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m173/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9969 - loss: 0.0125\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0126 - val_accuracy: 0.9873 - val_loss: 0.0301 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0130 - val_accuracy: 0.9887 - val_loss: 0.0300 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0102 - val_accuracy: 0.9873 - val_loss: 0.0308 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0120 - val_accuracy: 0.9901 - val_loss: 0.0295 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0164 - val_accuracy: 0.9894 - val_loss: 0.0285 - learning_rate: 5.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m168/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0120\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0120 - val_accuracy: 0.9887 - val_loss: 0.0304 - learning_rate: 5.0000e-04\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Test Accuracy: 99.39%\n",
      "Training model with params: {'learning_rate': 0.001, 'dropout_rate': 0.3, 'layers': 1, 'units': 64}\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5973 - loss: 0.6928 - val_accuracy: 0.8432 - val_loss: 0.4279 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3880 - val_accuracy: 0.9251 - val_loss: 0.2636 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9083 - loss: 0.2467 - val_accuracy: 0.9506 - val_loss: 0.1854 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9414 - loss: 0.1774 - val_accuracy: 0.9605 - val_loss: 0.1439 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1323 - val_accuracy: 0.9703 - val_loss: 0.1164 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9684 - loss: 0.1019 - val_accuracy: 0.9703 - val_loss: 0.0985 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.0919 - val_accuracy: 0.9774 - val_loss: 0.0829 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.0677 - val_accuracy: 0.9774 - val_loss: 0.0740 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.0619 - val_accuracy: 0.9753 - val_loss: 0.0677 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.0585 - val_accuracy: 0.9760 - val_loss: 0.0617 - learning_rate: 0.0010\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Test Accuracy: 86.09%\n",
      "Training model with params: {'learning_rate': 0.001, 'dropout_rate': 0.5, 'layers': 2, 'units': 32}\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5107 - loss: 0.8197 - val_accuracy: 0.6836 - val_loss: 0.6280 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6024 - loss: 0.6646 - val_accuracy: 0.8030 - val_loss: 0.5530 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6845 - loss: 0.5814 - val_accuracy: 0.8828 - val_loss: 0.3979 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7839 - loss: 0.4522 - val_accuracy: 0.9266 - val_loss: 0.2540 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8576 - loss: 0.3259 - val_accuracy: 0.9499 - val_loss: 0.1751 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8929 - loss: 0.2519 - val_accuracy: 0.9576 - val_loss: 0.1364 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9164 - loss: 0.2078 - val_accuracy: 0.9703 - val_loss: 0.1063 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9365 - loss: 0.1584 - val_accuracy: 0.9689 - val_loss: 0.0908 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9362 - loss: 0.1518 - val_accuracy: 0.9732 - val_loss: 0.0768 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1198 - val_accuracy: 0.9774 - val_loss: 0.0684 - learning_rate: 0.0010\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Test Accuracy: 71.78%\n",
      "Training model with params: {'learning_rate': 0.004, 'dropout_rate': 0.5, 'layers': 2, 'units': 64}\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\puspe\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6367 - loss: 0.6363 - val_accuracy: 0.9357 - val_loss: 0.1768 - learning_rate: 0.0040\n",
      "Epoch 2/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9073 - loss: 0.2252 - val_accuracy: 0.9605 - val_loss: 0.1029 - learning_rate: 0.0040\n",
      "Epoch 3/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9411 - loss: 0.1317 - val_accuracy: 0.9781 - val_loss: 0.0634 - learning_rate: 0.0040\n",
      "Epoch 4/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.1009 - val_accuracy: 0.9795 - val_loss: 0.0547 - learning_rate: 0.0040\n",
      "Epoch 5/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.0712 - val_accuracy: 0.9703 - val_loss: 0.0646 - learning_rate: 0.0040\n",
      "Epoch 6/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9686 - loss: 0.0756 - val_accuracy: 0.9760 - val_loss: 0.0557 - learning_rate: 0.0040\n",
      "Epoch 7/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9756 - loss: 0.0558 - val_accuracy: 0.9781 - val_loss: 0.0465 - learning_rate: 0.0040\n",
      "Epoch 8/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9829 - loss: 0.0465 - val_accuracy: 0.9816 - val_loss: 0.0537 - learning_rate: 0.0040\n",
      "Epoch 9/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9798 - loss: 0.0539 - val_accuracy: 0.9767 - val_loss: 0.0425 - learning_rate: 0.0040\n",
      "Epoch 10/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.0451 - val_accuracy: 0.9816 - val_loss: 0.0472 - learning_rate: 0.0040\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Test Accuracy: 94.89%\n",
      "Best parameters: {'learning_rate': 0.001, 'dropout_rate': 0.3, 'layers': 1, 'units': 32}\n",
      "Best Test Accuracy: 99.39%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Function to create a model\n",
    "def create_model(learning_rate=0.001, dropout_rate=0.5, layers=1, units=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_shape=(X_train_pca.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        \n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_pca)\n",
    "X_test_scaled = scaler.transform(X_test_pca)\n",
    "\n",
    "# Early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\n",
    "\n",
    "# Hyperparameter combinations to try\n",
    "hyperparams = [\n",
    "    {'learning_rate': 0.001, 'dropout_rate': 0.3, 'layers': 1, 'units': 32},\n",
    "    {'learning_rate': 0.001, 'dropout_rate': 0.3, 'layers': 1, 'units': 64},\n",
    "    {'learning_rate': 0.001, 'dropout_rate': 0.5, 'layers': 2, 'units': 32},\n",
    "    {'learning_rate': 0.004, 'dropout_rate': 0.5, 'layers': 2, 'units': 64},\n",
    "    # Add more combinations as needed\n",
    "]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_params = None\n",
    "\n",
    "# Train models with different hyperparameters\n",
    "for params in hyperparams:\n",
    "    print(f\"Training model with params: {params}\")\n",
    "    model = create_model(learning_rate=params['learning_rate'], \n",
    "                         dropout_rate=params['dropout_rate'],\n",
    "                         layers=params['layers'], \n",
    "                         units=params['units'])\n",
    "\n",
    "    model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, \n",
    "              validation_split=0.2, \n",
    "              callbacks=[early_stopping, lr_scheduler], verbose=1)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Save the best model\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best Test Accuracy: {best_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441f5226-be47-49a4-92a4-5dec054e5c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
